{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a867712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/mnt/LLM\n",
      "env: OMP_NUM_THREADS=16\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env HF_HOME=/mnt/LLM\n",
    "%env OMP_NUM_THREADS=16\n",
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4c1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "2025-07-30 18:37:01,649 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c849fc6f794ec0adc212d00e778ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "import torch\n",
    "from src.find_important_tokens_eagle import EaModelForAutoJudge\n",
    "from lm_eval_utils import GSM8KParser, GSM8KEvaluator\n",
    "from prompts import GSM8KPrompts, llama_assistant_turn_end\n",
    "\n",
    "base_model_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "EAGLE_model_path = \"yuhuili/EAGLE-LLaMA3.1-Instruct-8B\"\n",
    "window_size = 8\n",
    "\n",
    "model = EaModelForAutoJudge.from_pretrained(\n",
    "    base_model_path=base_model_path,\n",
    "    ea_model_path=EAGLE_model_path,\n",
    "    use_eagle3=\"eagle3\" in EAGLE_model_path.lower(),\n",
    "    torch_dtype=\"auto\", #was: torch.bfloat16\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,    \n",
    "    depth=window_size - 1,\n",
    "    total_token=window_size,\n",
    "    do_sample=False, top_p=None, top_k=1, temperature=None\n",
    ")\n",
    "device = next(model.parameters()).device\n",
    "tokenizer = model.get_tokenizer()\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe93400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = datasets.load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")\n",
    "(len(test_data) - 1) // 3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60910de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "trained_head = pd.read_pickle(\"./trained_head.pkl\")\n",
    "\n",
    "def classifier(hidden_states: torch.Tensor):\n",
    "    hidden_states = hidden_states.cpu().reshape(1, -1).float().numpy()\n",
    "    hidden_states = trained_head[\"scaler\"].transform(hidden_states)\n",
    "    p_important, = trained_head[\"model\"].predict_proba(hidden_states)[:, 1]\n",
    "    return p_important > 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5090e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 1\t| Running Acc: 1.00000 |\t Accepted: 3.2435897435897436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 2\t| Running Acc: 1.00000 |\t Accepted: 3.085714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 3\t| Running Acc: 1.00000 |\t Accepted: 2.949771689497717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 4\t| Running Acc: 1.00000 |\t Accepted: 2.942760942760943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 5\t| Running Acc: 1.00000 |\t Accepted: 2.966966966966967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 6\t| Running Acc: 1.00000 |\t Accepted: 2.972286374133949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 7\t| Running Acc: 1.00000 |\t Accepted: 2.937254901960784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 8\t| Running Acc: 1.00000 |\t Accepted: 2.910839160839161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 9\t| Running Acc: 1.00000 |\t Accepted: 2.932584269662921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 10\t| Running Acc: 1.00000 |\t Accepted: 2.957957957957958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 11\t| Running Acc: 0.90909 |\t Accepted: 2.9342465753424656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 12\t| Running Acc: 0.91667 |\t Accepted: 2.9505208333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 13\t| Running Acc: 0.92308 |\t Accepted: 2.9410348977135983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 14\t| Running Acc: 0.85714 |\t Accepted: 2.929281767955801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 15\t| Running Acc: 0.80000 |\t Accepted: 2.964021164021164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 16\t| Running Acc: 0.81250 |\t Accepted: 2.9693069306930693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 17\t| Running Acc: 0.82353 |\t Accepted: 2.9757462686567164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 18\t| Running Acc: 0.83333 |\t Accepted: 2.98125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 19\t| Running Acc: 0.84211 |\t Accepted: 2.989787234042553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 20\t| Running Acc: 0.85000 |\t Accepted: 3.002398081534772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 21\t| Running Acc: 0.85714 |\t Accepted: 3.0091603053435114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 22\t| Running Acc: 0.86364 |\t Accepted: 3.01620029455081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 23\t| Running Acc: 0.86957 |\t Accepted: 3.025399129172714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 24\t| Running Acc: 0.87500 |\t Accepted: 3.043661971830986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 25\t| Running Acc: 0.88000 |\t Accepted: 3.0396988364134154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 26\t| Running Acc: 0.88462 |\t Accepted: 3.026246719160105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 27\t| Running Acc: 0.85185 |\t Accepted: 3.0253807106598987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 28\t| Running Acc: 0.85714 |\t Accepted: 3.0333745364647715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 29\t| Running Acc: 0.86207 |\t Accepted: 3.045130641330166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 30\t| Running Acc: 0.86667 |\t Accepted: 3.0475638051044083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 31\t| Running Acc: 0.87097 |\t Accepted: 3.0494880546075085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 32\t| Running Acc: 0.87500 |\t Accepted: 3.0581073602656335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 33\t| Running Acc: 0.87879 |\t Accepted: 3.0609299839657935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 34\t| Running Acc: 0.88235 |\t Accepted: 3.059247810407007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 35\t| Running Acc: 0.88571 |\t Accepted: 3.067269076305221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 36\t| Running Acc: 0.86111 |\t Accepted: 3.067288801571709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 37\t| Running Acc: 0.86486 |\t Accepted: 3.0812109562710237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 38\t| Running Acc: 0.86842 |\t Accepted: 3.086697247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 39\t| Running Acc: 0.87179 |\t Accepted: 3.094831460674157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 40\t| Running Acc: 0.85000 |\t Accepted: 3.1015384615384614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 41\t| Running Acc: 0.85366 |\t Accepted: 3.109624514458351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 42\t| Running Acc: 0.85714 |\t Accepted: 3.1140313692242474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 43\t| Running Acc: 0.86047 |\t Accepted: 3.115802675585284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 44\t| Running Acc: 0.86364 |\t Accepted: 3.1140637775960753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 45\t| Running Acc: 0.86667 |\t Accepted: 3.1157852564102564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 46\t| Running Acc: 0.86957 |\t Accepted: 3.125345986555951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 47\t| Running Acc: 0.87234 |\t Accepted: 3.142025611175786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 48\t| Running Acc: 0.87500 |\t Accepted: 3.1430192962542565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 49\t| Running Acc: 0.87755 |\t Accepted: 3.146205357142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 50\t| Running Acc: 0.88000 |\t Accepted: 3.1435371658733064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 51\t| Running Acc: 0.88235 |\t Accepted: 3.144300144300144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 52\t| Running Acc: 0.88462 |\t Accepted: 3.1465670579864815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 53\t| Running Acc: 0.88679 |\t Accepted: 3.148448519040903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 54\t| Running Acc: 0.88889 |\t Accepted: 3.1535042735042733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 55\t| Running Acc: 0.87273 |\t Accepted: 3.1433311214333113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 56\t| Running Acc: 0.87500 |\t Accepted: 3.1414538310412574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 57\t| Running Acc: 0.87719 |\t Accepted: 3.141795865633075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 58\t| Running Acc: 0.87931 |\t Accepted: 3.145952836201402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 59\t| Running Acc: 0.88136 |\t Accepted: 3.1474842767295597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 60\t| Running Acc: 0.88333 |\t Accepted: 3.145246206255807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 61\t| Running Acc: 0.86885 |\t Accepted: 3.1394856278366112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 62\t| Running Acc: 0.87097 |\t Accepted: 3.1473465757485917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 63\t| Running Acc: 0.87302 |\t Accepted: 3.153553670663937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 64\t| Running Acc: 0.87500 |\t Accepted: 3.1565569035239744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 65\t| Running Acc: 0.87692 |\t Accepted: 3.156758272574313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 66\t| Running Acc: 0.86364 |\t Accepted: 3.1464276011953274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 67\t| Running Acc: 0.85075 |\t Accepted: 3.156936261381896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 68\t| Running Acc: 0.85294 |\t Accepted: 3.146772068511199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 69\t| Running Acc: 0.85507 |\t Accepted: 3.146867689108396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 70\t| Running Acc: 0.84286 |\t Accepted: 3.148471615720524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 71\t| Running Acc: 0.83099 |\t Accepted: 3.138930912758447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 72\t| Running Acc: 0.83333 |\t Accepted: 3.1402241594022415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 73\t| Running Acc: 0.83562 |\t Accepted: 3.138779527559055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 74\t| Running Acc: 0.83784 |\t Accepted: 3.1403166869671133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 75\t| Running Acc: 0.84000 |\t Accepted: 3.1424439624005784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 76\t| Running Acc: 0.84211 |\t Accepted: 3.140480152127407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 77\t| Running Acc: 0.84416 |\t Accepted: 3.142621015348288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 78\t| Running Acc: 0.84615 |\t Accepted: 3.142422825070159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 79\t| Running Acc: 0.84810 |\t Accepted: 3.1454169538249483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 80\t| Running Acc: 0.85000 |\t Accepted: 3.148206990467544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 81\t| Running Acc: 0.83951 |\t Accepted: 3.145908273381295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 82\t| Running Acc: 0.84146 |\t Accepted: 3.1485676215856095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 83\t| Running Acc: 0.84337 |\t Accepted: 3.1484238178633976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 84\t| Running Acc: 0.83333 |\t Accepted: 3.149750054336014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 85\t| Running Acc: 0.82353 |\t Accepted: 3.1405097956604173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 86\t| Running Acc: 0.82558 |\t Accepted: 3.1299691040164777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 87\t| Running Acc: 0.81609 |\t Accepted: 3.1335083821450214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 88\t| Running Acc: 0.81818 |\t Accepted: 3.132297270372584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 89\t| Running Acc: 0.82022 |\t Accepted: 3.1372970858595735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 90\t| Running Acc: 0.82222 |\t Accepted: 3.1275529865125242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 91\t| Running Acc: 0.81319 |\t Accepted: 3.129357972947228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 92\t| Running Acc: 0.81522 |\t Accepted: 3.129086809470124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 93\t| Running Acc: 0.81720 |\t Accepted: 3.1279048150213793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 94\t| Running Acc: 0.81915 |\t Accepted: 3.1335540838852096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 95\t| Running Acc: 0.82105 |\t Accepted: 3.1330667151427014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 96\t| Running Acc: 0.82292 |\t Accepted: 3.1271323397378343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 97\t| Running Acc: 0.82474 |\t Accepted: 3.126831011075384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 98\t| Running Acc: 0.82653 |\t Accepted: 3.130766501064585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 99\t| Running Acc: 0.82828 |\t Accepted: 3.1316113161131613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 100\t| Running Acc: 0.82000 |\t Accepted: 3.130321004884857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 101\t| Running Acc: 0.82178 |\t Accepted: 3.130359612724758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 102\t| Running Acc: 0.82353 |\t Accepted: 3.128057065217391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 103\t| Running Acc: 0.81553 |\t Accepted: 3.1291841883936082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 104\t| Running Acc: 0.81731 |\t Accepted: 3.1329103356152945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 105\t| Running Acc: 0.81905 |\t Accepted: 3.129491637688359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 106\t| Running Acc: 0.82075 |\t Accepted: 3.1299835255354203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 107\t| Running Acc: 0.82243 |\t Accepted: 3.126549249836921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 108\t| Running Acc: 0.81481 |\t Accepted: 3.124517994858612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 109\t| Running Acc: 0.81651 |\t Accepted: 3.1232636116876895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 110\t| Running Acc: 0.80909 |\t Accepted: 3.1235545699350546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 111\t| Running Acc: 0.81081 |\t Accepted: 3.129184347006129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 112\t| Running Acc: 0.81250 |\t Accepted: 3.128624883068288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 113\t| Running Acc: 0.81416 |\t Accepted: 3.1286776091669246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 114\t| Running Acc: 0.81579 |\t Accepted: 3.1349900291455746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 115\t| Running Acc: 0.81739 |\t Accepted: 3.1424242424242426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 116\t| Running Acc: 0.81897 |\t Accepted: 3.1439553813687064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 117\t| Running Acc: 0.81197 |\t Accepted: 3.144862604540024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 118\t| Running Acc: 0.81356 |\t Accepted: 3.15054082086235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 119\t| Running Acc: 0.81513 |\t Accepted: 3.1540389150943398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 120\t| Running Acc: 0.80833 |\t Accepted: 3.1440788520075373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 121\t| Running Acc: 0.80992 |\t Accepted: 3.145682933872365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 122\t| Running Acc: 0.81148 |\t Accepted: 3.1479833500789436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 123\t| Running Acc: 0.81301 |\t Accepted: 3.147957726363896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 124\t| Running Acc: 0.81452 |\t Accepted: 3.145591153955203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 125\t| Running Acc: 0.81600 |\t Accepted: 3.1524758030579325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 126\t| Running Acc: 0.81746 |\t Accepted: 3.1513671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 127\t| Running Acc: 0.81890 |\t Accepted: 3.1505599336374948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 128\t| Running Acc: 0.81250 |\t Accepted: 3.1532247021771873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 129\t| Running Acc: 0.81395 |\t Accepted: 3.150006763154335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 130\t| Running Acc: 0.81538 |\t Accepted: 3.1473755047106327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 131\t| Running Acc: 0.81679 |\t Accepted: 3.1400690387679235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 132\t| Running Acc: 0.81818 |\t Accepted: 3.139894319682959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 133\t| Running Acc: 0.81955 |\t Accepted: 3.1392571203570023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 134\t| Running Acc: 0.82090 |\t Accepted: 3.1380704041720993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 135\t| Running Acc: 0.81481 |\t Accepted: 3.1392977020397623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 136\t| Running Acc: 0.81618 |\t Accepted: 3.140570989630009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 137\t| Running Acc: 0.81752 |\t Accepted: 3.141444866920152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 138\t| Running Acc: 0.81159 |\t Accepted: 3.143646408839779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 139\t| Running Acc: 0.81295 |\t Accepted: 3.145625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 140\t| Running Acc: 0.81429 |\t Accepted: 3.1474390850323224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 141\t| Running Acc: 0.80851 |\t Accepted: 3.186865021770682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 142\t| Running Acc: 0.80986 |\t Accepted: 3.1885748647023453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 143\t| Running Acc: 0.81119 |\t Accepted: 3.189156914258419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 144\t| Running Acc: 0.80556 |\t Accepted: 3.185834419045363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 145\t| Running Acc: 0.80000 |\t Accepted: 3.1846063454759106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 146\t| Running Acc: 0.80137 |\t Accepted: 3.184826943246708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 147\t| Running Acc: 0.80272 |\t Accepted: 3.1847008448096283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 148\t| Running Acc: 0.80405 |\t Accepted: 3.1882177308222324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 149\t| Running Acc: 0.80537 |\t Accepted: 3.188629604209563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 150\t| Running Acc: 0.80000 |\t Accepted: 3.189768602540835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 151\t| Running Acc: 0.79470 |\t Accepted: 3.189167886499268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 152\t| Running Acc: 0.79605 |\t Accepted: 3.1880600358422937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 153\t| Running Acc: 0.79739 |\t Accepted: 3.1902797904358486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 154\t| Running Acc: 0.79221 |\t Accepted: 3.1892041675903346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 155\t| Running Acc: 0.79355 |\t Accepted: 3.190638766519824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 156\t| Running Acc: 0.79487 |\t Accepted: 3.1903303434697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 157\t| Running Acc: 0.79618 |\t Accepted: 3.1906521739130436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 158\t| Running Acc: 0.79747 |\t Accepted: 3.1912940159861742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 159\t| Running Acc: 0.79245 |\t Accepted: 3.191306219066064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 160\t| Running Acc: 0.79375 |\t Accepted: 3.190603595890411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 161\t| Running Acc: 0.79503 |\t Accepted: 3.1904559011504046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 162\t| Running Acc: 0.79012 |\t Accepted: 3.192689626030002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 163\t| Running Acc: 0.79141 |\t Accepted: 3.1931818181818183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 164\t| Running Acc: 0.79268 |\t Accepted: 3.1945951585976626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 165\t| Running Acc: 0.79394 |\t Accepted: 3.195534787123572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 166\t| Running Acc: 0.79518 |\t Accepted: 3.198823772183244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 167\t| Running Acc: 0.79641 |\t Accepted: 3.1966171194259356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 168\t| Running Acc: 0.79167 |\t Accepted: 3.181681077820229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 169\t| Running Acc: 0.79290 |\t Accepted: 3.182871989607275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 170\t| Running Acc: 0.79412 |\t Accepted: 3.1852514410653945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 171\t| Running Acc: 0.79532 |\t Accepted: 3.184306749678822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 172\t| Running Acc: 0.79070 |\t Accepted: 3.1884185773074663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 173\t| Running Acc: 0.79191 |\t Accepted: 3.1898487066861883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 174\t| Running Acc: 0.79310 |\t Accepted: 3.1904530429710287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 175\t| Running Acc: 0.79429 |\t Accepted: 3.1921439628482973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 176\t| Running Acc: 0.78977 |\t Accepted: 3.193088843969583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 177\t| Running Acc: 0.79096 |\t Accepted: 3.193186180422265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 178\t| Running Acc: 0.78652 |\t Accepted: 3.19346542198514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 179\t| Running Acc: 0.78771 |\t Accepted: 3.194473360461815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 180\t| Running Acc: 0.78889 |\t Accepted: 3.1972468414105224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 181\t| Running Acc: 0.79006 |\t Accepted: 3.199718309859155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 182\t| Running Acc: 0.79121 |\t Accepted: 3.2003740065451147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 183\t| Running Acc: 0.79235 |\t Accepted: 3.200576261734362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 184\t| Running Acc: 0.79348 |\t Accepted: 3.2002406961673766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 185\t| Running Acc: 0.79459 |\t Accepted: 3.200626959247649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 186\t| Running Acc: 0.79570 |\t Accepted: 3.202151130722559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 187\t| Running Acc: 0.79679 |\t Accepted: 3.199487554904832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 188\t| Running Acc: 0.79787 |\t Accepted: 3.20120229529101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 189\t| Running Acc: 0.79894 |\t Accepted: 3.201650194940611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 190\t| Running Acc: 0.80000 |\t Accepted: 3.201856357574119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 191\t| Running Acc: 0.80105 |\t Accepted: 3.20245563721097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 192\t| Running Acc: 0.80208 |\t Accepted: 3.205473346407559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 193\t| Running Acc: 0.80311 |\t Accepted: 3.207264008524998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 194\t| Running Acc: 0.80412 |\t Accepted: 3.2067592674511194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 195\t| Running Acc: 0.80513 |\t Accepted: 3.2054963445785254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 196\t| Running Acc: 0.80612 |\t Accepted: 3.2041137855579866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 197\t| Running Acc: 0.80711 |\t Accepted: 3.2021610317183686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 198\t| Running Acc: 0.80808 |\t Accepted: 3.2013184144331683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 199\t| Running Acc: 0.80402 |\t Accepted: 3.2013966721269074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 200\t| Running Acc: 0.80500 |\t Accepted: 3.2015463917525775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 201\t| Running Acc: 0.80597 |\t Accepted: 3.20285640981784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 202\t| Running Acc: 0.80198 |\t Accepted: 3.2009699651152896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 203\t| Running Acc: 0.80296 |\t Accepted: 3.2021968736797635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 204\t| Running Acc: 0.80392 |\t Accepted: 3.20355248758313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 205\t| Running Acc: 0.80488 |\t Accepted: 3.2031708749266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 206\t| Running Acc: 0.80583 |\t Accepted: 3.203360080240722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 207\t| Running Acc: 0.80676 |\t Accepted: 3.2036297036297037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 208\t| Running Acc: 0.80769 |\t Accepted: 3.2051197083920138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 209\t| Running Acc: 0.80861 |\t Accepted: 3.204740667327387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 210\t| Running Acc: 0.80476 |\t Accepted: 3.2041824468960973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 211\t| Running Acc: 0.80569 |\t Accepted: 3.205354949643822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 212\t| Running Acc: 0.80660 |\t Accepted: 3.205805822084892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 213\t| Running Acc: 0.80751 |\t Accepted: 3.20331983805668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 214\t| Running Acc: 0.80841 |\t Accepted: 3.2015172302477604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 215\t| Running Acc: 0.80930 |\t Accepted: 3.20213706113923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 216\t| Running Acc: 0.81019 |\t Accepted: 3.202769772654499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 217\t| Running Acc: 0.81106 |\t Accepted: 3.2031573911656834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 218\t| Running Acc: 0.81193 |\t Accepted: 3.205370620481449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 219\t| Running Acc: 0.81279 |\t Accepted: 3.2058264724509185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 220\t| Running Acc: 0.81364 |\t Accepted: 3.2057736175568317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 221\t| Running Acc: 0.81448 |\t Accepted: 3.20538299037634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 222\t| Running Acc: 0.81532 |\t Accepted: 3.2068266832917707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 223\t| Running Acc: 0.81166 |\t Accepted: 3.2083042297244857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 224\t| Running Acc: 0.81250 |\t Accepted: 3.2088524336454385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 225\t| Running Acc: 0.81333 |\t Accepted: 3.210108637029047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 226\t| Running Acc: 0.81416 |\t Accepted: 3.211928154743629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 227\t| Running Acc: 0.81498 |\t Accepted: 3.211200976651915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 228\t| Running Acc: 0.81579 |\t Accepted: 3.213072293745715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 229\t| Running Acc: 0.81659 |\t Accepted: 3.2140414862092546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 230\t| Running Acc: 0.81739 |\t Accepted: 3.214561416786498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 231\t| Running Acc: 0.81818 |\t Accepted: 3.2151698113207545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 232\t| Running Acc: 0.81897 |\t Accepted: 3.2151993980436417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 233\t| Running Acc: 0.81545 |\t Accepted: 3.2112697107839474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 234\t| Running Acc: 0.81624 |\t Accepted: 3.2108124208801847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 235\t| Running Acc: 0.81702 |\t Accepted: 3.209336791404224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 236\t| Running Acc: 0.81356 |\t Accepted: 3.2042662743655757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 237\t| Running Acc: 0.81435 |\t Accepted: 3.203427065026362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 238\t| Running Acc: 0.81513 |\t Accepted: 3.2030964726502593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 239\t| Running Acc: 0.81590 |\t Accepted: 3.2019195811822874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 240\t| Running Acc: 0.81667 |\t Accepted: 3.2017403915881073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 241\t| Running Acc: 0.81743 |\t Accepted: 3.200202370627349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 242\t| Running Acc: 0.81818 |\t Accepted: 3.200043174785925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 243\t| Running Acc: 0.81893 |\t Accepted: 3.200172006020211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 244\t| Running Acc: 0.81967 |\t Accepted: 3.1989147508210767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 245\t| Running Acc: 0.82041 |\t Accepted: 3.2007119971520113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 246\t| Running Acc: 0.82114 |\t Accepted: 3.2025001775694295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 247\t| Running Acc: 0.82186 |\t Accepted: 3.2015997734834007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 248\t| Running Acc: 0.81855 |\t Accepted: 3.1986055356010987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 249\t| Running Acc: 0.81928 |\t Accepted: 3.19743121841662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 250\t| Running Acc: 0.81600 |\t Accepted: 3.1982927511894768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 251\t| Running Acc: 0.81673 |\t Accepted: 3.198858495162525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 252\t| Running Acc: 0.81746 |\t Accepted: 3.2001107879795043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 253\t| Running Acc: 0.81818 |\t Accepted: 3.201655172413793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 254\t| Running Acc: 0.81890 |\t Accepted: 3.202775106470669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 255\t| Running Acc: 0.81961 |\t Accepted: 3.2033053336065014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 256\t| Running Acc: 0.82031 |\t Accepted: 3.2032570182611066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 257\t| Running Acc: 0.82101 |\t Accepted: 3.2019647696476965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 258\t| Running Acc: 0.82171 |\t Accepted: 3.2017715869903305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 259\t| Running Acc: 0.82239 |\t Accepted: 3.2025316455696204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 260\t| Running Acc: 0.82308 |\t Accepted: 3.204475204945572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 261\t| Running Acc: 0.82375 |\t Accepted: 3.2054849498327758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 262\t| Running Acc: 0.82443 |\t Accepted: 3.2057648781786714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 263\t| Running Acc: 0.82510 |\t Accepted: 3.206231355651309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 264\t| Running Acc: 0.82576 |\t Accepted: 3.2061406404754043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 265\t| Running Acc: 0.82642 |\t Accepted: 3.2049779416606308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 266\t| Running Acc: 0.82707 |\t Accepted: 3.204782865777544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 267\t| Running Acc: 0.82772 |\t Accepted: 3.2042124542124544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 268\t| Running Acc: 0.82836 |\t Accepted: 3.207062809486578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 269\t| Running Acc: 0.82900 |\t Accepted: 3.208281869596308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 270\t| Running Acc: 0.82963 |\t Accepted: 3.2104648900992023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 271\t| Running Acc: 0.82657 |\t Accepted: 3.2117297506782068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 272\t| Running Acc: 0.82353 |\t Accepted: 3.2090558766859343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 273\t| Running Acc: 0.82051 |\t Accepted: 3.207283627782384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 274\t| Running Acc: 0.82117 |\t Accepted: 3.206495487479344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 275\t| Running Acc: 0.82182 |\t Accepted: 3.2072853975293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 276\t| Running Acc: 0.82246 |\t Accepted: 3.208470083312295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 277\t| Running Acc: 0.82310 |\t Accepted: 3.2098284421542136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 278\t| Running Acc: 0.82374 |\t Accepted: 3.2117905299466916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 279\t| Running Acc: 0.82437 |\t Accepted: 3.2126038348635313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 280\t| Running Acc: 0.82500 |\t Accepted: 3.2124345875903315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 281\t| Running Acc: 0.82562 |\t Accepted: 3.2137622655570737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 282\t| Running Acc: 0.82270 |\t Accepted: 3.2123440009885087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 283\t| Running Acc: 0.82332 |\t Accepted: 3.2109476017486607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 284\t| Running Acc: 0.82394 |\t Accepted: 3.210865561694291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 285\t| Running Acc: 0.82105 |\t Accepted: 3.210343143240933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 286\t| Running Acc: 0.82168 |\t Accepted: 3.211436575117228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 287\t| Running Acc: 0.82230 |\t Accepted: 3.212150609349421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 288\t| Running Acc: 0.82292 |\t Accepted: 3.2140484387268224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 289\t| Running Acc: 0.82007 |\t Accepted: 3.2147804613624045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 290\t| Running Acc: 0.81724 |\t Accepted: 3.2180086268871317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 291\t| Running Acc: 0.81787 |\t Accepted: 3.218929254302103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 292\t| Running Acc: 0.81849 |\t Accepted: 3.217752955855267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 293\t| Running Acc: 0.81911 |\t Accepted: 3.2198934280639433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 294\t| Running Acc: 0.81973 |\t Accepted: 3.2199562570195663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 295\t| Running Acc: 0.82034 |\t Accepted: 3.2205587645879996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 296\t| Running Acc: 0.82095 |\t Accepted: 3.220381791483113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 297\t| Running Acc: 0.82155 |\t Accepted: 3.219893448861308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 298\t| Running Acc: 0.82215 |\t Accepted: 3.2195691517309823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:275: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "accepted_tokens_history = []\n",
    "num_steps_history = []\n",
    "accuracy_history = []\n",
    "parser, evaluator = GSM8KParser(), GSM8KEvaluator()\n",
    "\n",
    "for sample in test_data.select(range(440,880)):\n",
    "    prompt_with_shots = GSM8KPrompts.prompt_with_0_shots\n",
    "    prompt = prompt_with_shots + sample[\"question\"] + \"\\n\" + GSM8KPrompts.formatting_prompt + llama_assistant_turn_end\n",
    "    batch_input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "    output_dict = current_response = model.eagenerate_with_statistics(\n",
    "        input_ids=batch_input_ids, max_new_tokens=1024, max_length=4096, classifier=classifier\n",
    "    )\n",
    "    response_str = tokenizer.decode(output_dict[\"input_ids\"].flatten())\n",
    "\n",
    "    accuracy_history.append(evaluator([response_str], [sample[\"answer\"]]))\n",
    "    num_steps_history.append(len(output_dict[\"step_statistics\"]))\n",
    "    accepted_tokens_history.extend([d[\"accepted_tokens\"] for d in output_dict[\"step_statistics\"]])\n",
    "    print(f\"Samples: {len(accuracy_history)}\\t|\",\n",
    "          f\"Running Acc: {np.mean(accuracy_history):.5f}\",\n",
    "          f\"|\\t Accepted: {np.mean(accepted_tokens_history)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f5afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
