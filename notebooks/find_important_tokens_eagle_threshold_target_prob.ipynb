{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a867712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/mnt/LLM\n",
      "env: OMP_NUM_THREADS=16\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env HF_HOME=/mnt/LLM\n",
    "%env OMP_NUM_THREADS=16\n",
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4c1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ACHTUNG: Model will be loaded twice! This can be optimized.\n",
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f358fd8088a04b1ab65b17446400fd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1723704b9f314ebca2e95d5e5f6ec36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from src.find_important_tokens_eagle import EaModelForAutoJudge\n",
    "from prompts import GSM8KPrompts, llama_assistant_turn_end\n",
    "\n",
    "base_model_path = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "EAGLE_model_path = \"yuhuili/EAGLE3-LLaMA3.1-Instruct-8B\"\n",
    "window_size = 16\n",
    "\n",
    "model = EaModelForAutoJudge.from_pretrained_with_tied_ref_model(\n",
    "    base_model_path=base_model_path,\n",
    "    ea_model_path=EAGLE_model_path,\n",
    "    use_eagle3=\"eagle3\" in EAGLE_model_path.lower(),\n",
    "    torch_dtype=\"auto\", #was: torch.bfloat16\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True,    \n",
    "    depth=window_size - 1,\n",
    "    total_token=window_size,\n",
    "    do_sample=False, top_p=None, top_k=1, temperature=None\n",
    ")\n",
    "device = next(model.parameters()).device\n",
    "tokenizer = model.get_tokenizer()\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f323ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
    "prompt_with_shots = GSM8KPrompts.prompt_with_0_shots\n",
    "prompt = prompt_with_shots + question + \"\\n\" + GSM8KPrompts.formatting_prompt + llama_assistant_turn_end\n",
    "batch_input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da7bc03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jheuristic/exp/speculation_for_reasoning/notebooks/../src/find_important_tokens_eagle.py:85: UserWarning: Model recognized as Llama 3.x\n",
      "  warnings.warn(\"Model recognized as Llama 3.x\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT IMPORTANT\n",
      "accept_length before tensor(6, device='cuda:0')\n",
      "accept_length after 7\n",
      "NOT IMPORTANT\n",
      "accept_length before 7\n",
      "accept_length after 9\n",
      "BAD logp: ... t_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTo find the total number of clips sold in April |  April [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... <|end_header_id|>\\n\\nTo find the total number of clips sold in April and May, we need to calculate the |  how [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ...  find the total number of clips sold in April and May, we need to calculate the number of clips sold |  by [logp=0.00002]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(0, device='cuda:0')\n",
      "accept_length after 1\n",
      "BAD logp: ... he total number of clips sold in April and May, we need to calculate the number of clips sold in May |  separately [logp=0.00019]\n",
      "IMPORTANT\n",
      "BAD logp: ... al number of clips sold in April and May, we need to calculate the number of clips sold in May first |  clip [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... umber of clips sold in April and May, we need to calculate the number of clips sold in May first. \\n\\n | Number [logp=0.00952]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(0, device='cuda:0')\n",
      "accept_length after 8\n",
      "BAD logp: ...  need to calculate the number of clips sold in May first. \\n\\nSince she sold half as many clips in May |  April [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... ed to calculate the number of clips sold in May first. \\n\\nSince she sold half as many clips in May as |  the [logp=0.00023]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(2, device='cuda:0')\n",
      "accept_length after 11\n",
      "NOT IMPORTANT\n",
      "accept_length before 11\n",
      "accept_length after 12\n",
      "BAD logp: ... \\nSince she sold half as many clips in May as in April, we can find the number of clips sold in April |  April [logp=0.00000]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(0, device='cuda:0')\n",
      "accept_length after 1\n",
      "NOT IMPORTANT\n",
      "accept_length before 1\n",
      "accept_length after 3\n",
      "BAD logp: ... f as many clips in May as in April, we can find the number of clips sold in April and divide that by |  this [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... as many clips in May as in April, we can find the number of clips sold in April and divide that by 2 |  ( [logp=0.00004]\n",
      "IMPORTANT\n",
      "BAD logp: ...  number of clips sold in April and divide that by 2 to find the number of clips sold in May.\\n\\nNumber | in [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... ps sold in April and divide that by 2 to find the number of clips sold in May.\\n\\nNumber of clips sold |  April [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... il and divide that by 2 to find the number of clips sold in May.\\n\\nNumber of clips sold in April = 48 |  ( [logp=0.00016]\n",
      "IMPORTANT\n",
      "BAD logp: ...  the number of clips sold in May.\\n\\nNumber of clips sold in April = 48\\nNumber of clips sold in May =  | 2 [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... he number of clips sold in May.\\n\\nNumber of clips sold in April = 48\\nNumber of clips sold in May = 48 |  * [logp=0.00055]\n",
      "IMPORTANT\n",
      "BAD logp: ... umber of clips sold in May.\\n\\nNumber of clips sold in April = 48\\nNumber of clips sold in May = 48 / 2 | I [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... er of clips sold in May.\\n\\nNumber of clips sold in April = 48\\nNumber of clips sold in May = 48 / 2 =  | 18 [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ...  of clips sold in May.\\n\\nNumber of clips sold in April = 48\\nNumber of clips sold in May = 48 / 2 = 24 |  clips [logp=0.00016]\n",
      "IMPORTANT\n",
      "BAD logp: ... f clips sold in May.\\n\\nNumber of clips sold in April = 48\\nNumber of clips sold in May = 48 / 2 = 24\\n\\n | Number [logp=0.00008]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(0, device='cuda:0')\n",
      "accept_length after 1\n",
      "NOT IMPORTANT\n",
      "accept_length before 1\n",
      "accept_length after 10\n",
      "BAD logp: ... ril = 48\\nNumber of clips sold in May = 48 / 2 = 24\\n\\nNow we add the number of clips sold in April and |  Add [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ...  48 / 2 = 24\\n\\nNow we add the number of clips sold in April and May to find the total number of clips |  clips [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ...  2 = 24\\n\\nNow we add the number of clips sold in April and May to find the total number of clips sold |  clip [logp=0.00000]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(5, device='cuda:0')\n",
      "accept_length after 7\n",
      "BAD logp: ... s sold in April and May to find the total number of clips sold.\\n\\nTotal number of clips sold in April |  = [logp=0.00030]\n",
      "IMPORTANT\n",
      "BAD logp: ... d May to find the total number of clips sold.\\n\\nTotal number of clips sold in April and May = 48 + 24 | Cl [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... ay to find the total number of clips sold.\\n\\nTotal number of clips sold in April and May = 48 + 24 =  | 48 [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... o find the total number of clips sold.\\n\\nTotal number of clips sold in April and May = 48 + 24 = 72\\n\\n | Therefore [logp=0.00043]\n",
      "IMPORTANT\n",
      "BAD logp: ... e total number of clips sold.\\n\\nTotal number of clips sold in April and May = 48 + 24 = 72\\n\\nThe final |  Answer [logp=0.00000]\n",
      "IMPORTANT\n",
      "BAD logp: ... mber of clips sold.\\n\\nTotal number of clips sold in April and May = 48 + 24 = 72\\n\\nThe final answer is |  ( [logp=0.00000]\n",
      "IMPORTANT\n",
      "NOT IMPORTANT\n",
      "accept_length before tensor(1, device='cuda:0')\n",
      "accept_length after 2\n",
      "BAD logp: ...  sold.\\n\\nTotal number of clips sold in April and May = 48 + 24 = 72\\n\\nThe final answer is 72<|eot_id|> | <|eot_id|> [logp=0.00000]\n",
      "IMPORTANT\n",
      "==================================================\n",
      "================= FINAL RESPONSE =================\n",
      "==================================================\n",
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Given the following problem, reason and give a final answer to the problem.\n",
      "Problem: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Your response should end with \"The final answer is [answer]\" where [answer] is the response to the problem.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To find the total number of clips sold in April and May, we need to calculate the number of clips sold in May first. \n",
      "\n",
      "Since she sold half as many clips in May as in April, we can find the number of clips sold in April and divide that by 2 to find the number of clips sold in May.\n",
      "\n",
      "Number of clips sold in April = 48\n",
      "Number of clips sold in May = 48 / 2 = 24\n",
      "\n",
      "Now we add the number of clips sold in April and May to find the total number of clips sold.\n",
      "\n",
      "Total number of clips sold in April and May = 48 + 24 = 72\n",
      "\n",
      "The final answer is 72<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# this prints a lot of logs; scroll down to get the actual sanity checks\n",
    "current_response, changed_token_indices = model.find_important_tokens_greedy(\n",
    "    input_ids=batch_input_ids, max_new_tokens=256\n",
    ")\n",
    "print('='*50)\n",
    "print('=' * 17, 'FINAL RESPONSE', '=' * 17)\n",
    "print('='*50)\n",
    "print(*tokenizer.batch_decode(current_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e21e489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important tokens check passed!\n"
     ]
    }
   ],
   "source": [
    "for mismatch in changed_token_indices:\n",
    "    if mismatch[\"is_important\"]:\n",
    "        assert current_response[0, mismatch['mismatch_index']].item() == mismatch['mismatch_target_token']\n",
    "    else:\n",
    "        assert current_response[0, mismatch['mismatch_index']].item() == mismatch['mismatch_draft_token']\n",
    "print(\"Important tokens check passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eabccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our_answer='72', target_answer='72.', match=True\n"
     ]
    }
   ],
   "source": [
    "from lm_eval_utils import GSM8KParser, GSM8KEvaluator\n",
    "parser, evaluator = GSM8KParser(), GSM8KEvaluator()\n",
    "target_response = model.ref_model.eagenerate(batch_input_ids, max_new_tokens=256)\n",
    "\n",
    "our_answer, target_answer = parser([\n",
    "    *tokenizer.batch_decode(current_response), *tokenizer.batch_decode(target_response)])\n",
    "is_match = evaluator(generations=tokenizer.batch_decode(current_response), references=[target_answer]) == 1\n",
    "print(f\"{our_answer=}, {target_answer=}, match={is_match}\")\n",
    "assert is_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b758290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important rate: 0.7073170731707317\n"
     ]
    }
   ],
   "source": [
    "print(\"Important rate:\",\n",
    "      sum(mismatch[\"is_important\"] for mismatch in changed_token_indices) / len(changed_token_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72b8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
